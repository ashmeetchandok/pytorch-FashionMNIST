{
 Hey! Ashmeet
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch \n",
    "import torch.nn as nn\n",
    "import torchvision.datasets as dsets\n",
    "from skimage import transform\n",
    "import torchvision.transforms as transforms\n",
    "from torch.autograd import Variable\n",
    "import pandas as pd;\n",
    "import numpy as np;\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import random;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 5;\n",
    "batch_size = 100;\n",
    "learning_rate = 0.001;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FashionMNISTDataset(Dataset):\n",
    "    '''Fashion MNIST Dataset'''\n",
    "    def __init__(self, csv_file, transform=None,download=False):\n",
    "        data = pd.read_csv(\"/home/ashmeetkaur/Downloads/mnist_train.csv\");\n",
    "        self.X = np.array(data.iloc[:, 1:]).reshape(-1, 1, 28, 28)#.astype(float);\n",
    "        self.Y = np.array(data.iloc[:, 0]);\n",
    "        \n",
    "        del data;\n",
    "        self.transform = transform;\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.X);\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        item = self.X[idx];\n",
    "        label = self.Y[idx];\n",
    "        \n",
    "        if self.transform:\n",
    "            item = self.transform(item);\n",
    "        \n",
    "        return (item, label);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = FashionMNISTDataset(csv_file=\"/home/ashmeetkaur/Downloads/mnist_train.csv\");\n",
    "test_dataset = FashionMNISTDataset(csv_file=\"/home/ashmeetkaur/Downloads/mnist_test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = FashionMNISTDataset(csv_file=\"/home/ashmeetkaur/Downloads/mnist_train.csv\");\n",
    "test_dataset = FashionMNISTDataset(csv_file=\"/home/ashmeetkaur/Downloads/mnist_test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_map = {0 : 'T-Shirt', 1 : 'Trouser', 2 : 'Pullover', 3 : 'Dress', 4 : 'Coat', 5 : 'Sandal', 6 : 'Shirt',\n",
    "              7 : 'Sneaker', 8 : 'Bag', 9 : 'Ankle Boot'};"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "fig = plt.figure(figsize=(8,8));\n",
    "columns = 4;\n",
    "rows = 5;\n",
    "for i in range(1, columns*rows +1):\n",
    "    img_xy = np.random.randint(len(train_dataset));\n",
    "    img = train_dataset[img_xy][0][0,:,:]\n",
    "    fig.add_subplot(rows, columns, i)\n",
    "    plt.title(labels_map[train_dataset[img_xy][1]])\n",
    "    plt.axis('off')\n",
    "    plt.imshow(img, cmap='gray')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNNmodel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNNmodel, self).__init__()\n",
    "        #convolutional layer 1\n",
    "        self.cnn1=nn.Conv2d(in_channels=1, out_channels=16, kernel_size=5, padding=2)\n",
    "        self.relu1=nn.ReLU()\n",
    "        self.batchnorm1=nn.BatchNorm2d(16)\n",
    "        \n",
    "        #Maxpool 1\n",
    "        self.maxpool1=nn.MaxPool2d(kernel_size=2)\n",
    "        \n",
    "         #convolutional layer 2\n",
    "        self.cnn2=nn.Conv2d(in_channels=16, out_channels=32, kernel_size=5, padding=2)\n",
    "        self.relu2=nn.ReLU()\n",
    "        self.batchnorm2=nn.BatchNorm2d(32)\n",
    "        \n",
    "        #Maxpool 2\n",
    "        self.maxpool2=nn.MaxPool2d(kernel_size=2)\n",
    "        \n",
    "        self.dropout = nn.Dropout(p=0.5)\n",
    "        \n",
    "        #Linear Layer\n",
    "        self.fc1=nn.Linear(32*7*7, 10)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        #Convolution 1\n",
    "        out=self.cnn1(x)\n",
    "        out=self.relu1(out)\n",
    "        out=self.batchnorm1(out)\n",
    "        \n",
    "        #Maxpool 1\n",
    "        out=self.maxpool1(out)\n",
    "        \n",
    "        #Convolution 2\n",
    "        out=self.cnn2(out)\n",
    "        out=self.relu2(out)\n",
    "        out=self.batchnorm2(out)\n",
    "        \n",
    "        #Maxpool 2\n",
    "        out=self.maxpool2(out)\n",
    "        \n",
    "        out=out.view(out.size(0),-1)\n",
    "        out = self.dropout(out)\n",
    "        out=self.fc1(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn = CNNmodel();\n",
    "criterion = nn.CrossEntropyLoss();\n",
    "optimizer = torch.optim.Adam(cnn.parameters(), lr=learning_rate);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "losses = [];\n",
    "for epoch in range(num_epochs):\n",
    "    for i, (images, labels) in enumerate(train_loader):\n",
    "        images = Variable(images.float())\n",
    "        labels = Variable(labels)\n",
    "        correct=0\n",
    "        total=0\n",
    "        # Forward + Backward + Optimize\n",
    "        optimizer.zero_grad()\n",
    "        outputs = cnn(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        #outputs=model(images)\n",
    "        _, predicted=torch.max(outputs.data,1)\n",
    "        total+=labels.size(0)\n",
    "        correct+= (predicted==labels).sum()\n",
    "        accuracy=100*(float(correct)/float(total))\n",
    "        losses.append(loss.data[0]);\n",
    "        \n",
    "        if (i+1) % 100 == 0:\n",
    "            print ('Epoch : %d/%d, Iter : %d/%d,  Loss: %.4f, Accuracy=%f' \n",
    "                   %(epoch+1, num_epochs, i+1, len(train_dataset)//batch_size, loss.data[0], accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn.eval()\n",
    "correct = 0\n",
    "total = 0\n",
    "for images, labels in test_loader:\n",
    "    images = Variable(images.float())\n",
    "    outputs = cnn(images)\n",
    "    _, predicted = torch.max(outputs.data, 1)\n",
    "    total += labels.size(0)\n",
    "    correct += (predicted == labels).sum()\n",
    "print('Test Accuracy of the model on the 10000 test images: %.4f %%' % (100 * correct / total))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
