{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#IMPORTING MODULES\n",
    "import torch \n",
    "import torch.nn as nn\n",
    "import torchvision.datasets as dsets\n",
    "from skimage import transform\n",
    "import torchvision.transforms as transforms\n",
    "from torch.autograd import Variable\n",
    "import pandas as pd;\n",
    "import numpy as np;\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import random;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 5;\n",
    "batch_size = 100;\n",
    "learning_rate = 0.001;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#THIS IS THE DATASET CLASS. IT INHERITS THE 'DATASET' TYPE.\n",
    "class FashionMNISTDataset(Dataset):\n",
    "    '''Fashion MNIST Dataset'''\n",
    "    def __init__(self, csv_file, transform=None,download=False):\n",
    "        data = pd.read_csv(\"/home/ashmeetkaur/Downloads/mnist_train.csv\");\n",
    "        self.X = np.array(data.iloc[:, 1:]).reshape(-1, 1, 28, 28)#.astype(float);\n",
    "        self.Y = np.array(data.iloc[:, 0]);\n",
    "        \n",
    "        del data;\n",
    "        self.transform = transform;\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.X);\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        item = self.X[idx];\n",
    "        label = self.Y[idx];\n",
    "        \n",
    "        if self.transform:\n",
    "            item = self.transform(item);\n",
    "        \n",
    "        return (item, label);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#THIS IS FOR CONVERTING THE FILES CONTAINING THE DATA TO .CSV FILE\n",
    "def convert(imgf, labelf, outf, n):\n",
    "    f = open(imgf, \"rb\")\n",
    "    o = open(outf, \"w\")\n",
    "    l = open(labelf, \"rb\")\n",
    "\n",
    "    f.read(16)\n",
    "    l.read(8)\n",
    "    images = []\n",
    "\n",
    "    for i in range(n):\n",
    "        image = [ord(l.read(1))]\n",
    "        for j in range(28*28):\n",
    "            image.append(ord(f.read(1)))\n",
    "        images.append(image)\n",
    "\n",
    "    for image in images:\n",
    "        o.write(\",\".join(str(pix) for pix in image)+\"\\n\")\n",
    "    f.close()\n",
    "    o.close()\n",
    "    l.close()\n",
    "\n",
    "convert(\"/home/ashmeetkaur/Downloads/train-images-idx3-ubyte\", \"/home/ashmeetkaur/Downloads/train-labels-idx1-ubyte\",\"/home/ashmeetkaur/Downloadsmnist_train.csv\", 60000)\n",
    "convert(\"/home/ashmeetkaur/Downloads/t10k-images-idx3-ubyte\", \"/home/ashmeetkaur/Downloads/t10k-labels-idx1-ubyte\",\"/home/ashmeetkaur/Downloads/mnist_test.csv\", 10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = FashionMNISTDataset(csv_file=\"/home/ashmeetkaur/Downloads/mnist_train.csv\");\n",
    "test_dataset = FashionMNISTDataset(csv_file=\"/home/ashmeetkaur/Downloads/mnist_test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = torch.utils.data.DataLoader(dataset=train_dataset, batch_size=batch_size, shuffle=True);\n",
    "test_loader = torch.utils.data.DataLoader(dataset=test_dataset, batch_size=batch_size, shuffle=True);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_map = {0 : 'T-Shirt', 1 : 'Trouser', 2 : 'Pullover', 3 : 'Dress', 4 : 'Coat', 5 : 'Sandal', 6 : 'Shirt',\n",
    "              7 : 'Sneaker', 8 : 'Bag', 9 : 'Ankle Boot'};"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f1c9549d7b8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#FOR VISUALISING THE IMAGES\n",
    "import matplotlib.pyplot as plt\n",
    "fig = plt.figure(figsize=(8,8));\n",
    "columns = 4;\n",
    "rows = 5;\n",
    "for i in range(1, columns*rows +1):\n",
    "    img_xy = np.random.randint(len(train_dataset));\n",
    "    img = train_dataset[img_xy][0][0,:,:]\n",
    "    fig.add_subplot(rows, columns, i)\n",
    "    plt.title(labels_map[train_dataset[img_xy][1]])\n",
    "    plt.axis('off')\n",
    "    plt.imshow(img, cmap='gray')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#THIS IS THE MODEL. WE HAVE USED 2 CONVOLUTIONAL LAYERS. \n",
    "class CNNmodel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNNmodel, self).__init__()\n",
    "#CONVOLUTIONAL LAYER 1\n",
    "        self.cnn1=nn.Conv2d(in_channels=1, out_channels=16, kernel_size=5, padding=2)\n",
    "        self.relu1=nn.ReLU()\n",
    "        #self.batchnorm1=nn.BatchNorm2d(16)      \n",
    "#MAXPOOL 1\n",
    "        self.maxpool1=nn.MaxPool2d(kernel_size=2) \n",
    "    \n",
    "#CONVOLUTIONAL LAYER 2\n",
    "        self.cnn2=nn.Conv2d(in_channels=16, out_channels=32, kernel_size=5, padding=2)\n",
    "        self.relu2=nn.ReLU()\n",
    "        #self.batchnorm2=nn.BatchNorm2d(32)      \n",
    "#MAXPOOL 2\n",
    "        self.maxpool2=nn.MaxPool2d(kernel_size=2)\n",
    "       \n",
    "        #self.dropout = nn.Dropout(p=0.5)\n",
    "        \n",
    "#LINEAR LAYER\n",
    "        self.fc1=nn.Linear(32*7*7, 10)\n",
    "        \n",
    "    def forward(self, x):\n",
    "#CONVOLUTION 1\n",
    "        out=self.cnn1(x)\n",
    "        out=self.relu1(out)\n",
    "        #out=self.batchnorm1(out)        \n",
    "#MAXPOOL 1\n",
    "        out=self.maxpool1(out)\n",
    "        \n",
    "#CONVOLUTION 2\n",
    "        out=self.cnn2(out)\n",
    "        out=self.relu2(out)\n",
    "        #out=self.batchnorm2(out)\n",
    "#MAXPOOL 2\n",
    "        out=self.maxpool2(out)\n",
    "        \n",
    "        out=out.view(out.size(0),-1)\n",
    "        #out = self.dropout(out)\n",
    "        \n",
    "#LINEAR LAYER\n",
    "        out=self.fc1(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#INSTANCE OF THE MODEL\n",
    "cnn = CNNmodel();\n",
    "#LOSS\n",
    "criterion = nn.CrossEntropyLoss();\n",
    "#OPTIMIZER\n",
    "optimizer = torch.optim.Adam(cnn.parameters(), lr=learning_rate);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ashmeetkaur/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:19: UserWarning: invalid index of a 0-dim tensor. This will be an error in PyTorch 0.5. Use tensor.item() to convert a 0-dim tensor to a Python number\n",
      "/home/ashmeetkaur/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:23: UserWarning: invalid index of a 0-dim tensor. This will be an error in PyTorch 0.5. Use tensor.item() to convert a 0-dim tensor to a Python number\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 1/5, Iter : 100/599,  Loss: 0.3719, Accuracy=89.000000\n",
      "Epoch : 1/5, Iter : 200/599,  Loss: 0.4566, Accuracy=85.000000\n",
      "Epoch : 1/5, Iter : 300/599,  Loss: 0.2714, Accuracy=90.000000\n",
      "Epoch : 1/5, Iter : 400/599,  Loss: 0.4518, Accuracy=86.000000\n",
      "Epoch : 1/5, Iter : 500/599,  Loss: 0.4410, Accuracy=85.000000\n",
      "Epoch : 1/5, Iter : 600/599,  Loss: 0.3732, Accuracy=87.878788\n",
      "Epoch : 2/5, Iter : 100/599,  Loss: 0.4880, Accuracy=80.000000\n",
      "Epoch : 2/5, Iter : 200/599,  Loss: 0.2181, Accuracy=93.000000\n",
      "Epoch : 2/5, Iter : 300/599,  Loss: 0.5320, Accuracy=83.000000\n",
      "Epoch : 2/5, Iter : 400/599,  Loss: 0.2704, Accuracy=92.000000\n",
      "Epoch : 2/5, Iter : 500/599,  Loss: 0.3278, Accuracy=90.000000\n",
      "Epoch : 2/5, Iter : 600/599,  Loss: 0.3039, Accuracy=87.878788\n",
      "Epoch : 3/5, Iter : 100/599,  Loss: 0.2871, Accuracy=89.000000\n",
      "Epoch : 3/5, Iter : 200/599,  Loss: 0.2704, Accuracy=91.000000\n",
      "Epoch : 3/5, Iter : 300/599,  Loss: 0.1903, Accuracy=92.000000\n",
      "Epoch : 3/5, Iter : 400/599,  Loss: 0.2132, Accuracy=93.000000\n",
      "Epoch : 3/5, Iter : 500/599,  Loss: 0.3398, Accuracy=87.000000\n",
      "Epoch : 3/5, Iter : 600/599,  Loss: 0.3287, Accuracy=85.858586\n",
      "Epoch : 4/5, Iter : 100/599,  Loss: 0.3068, Accuracy=89.000000\n",
      "Epoch : 4/5, Iter : 200/599,  Loss: 0.3660, Accuracy=88.000000\n",
      "Epoch : 4/5, Iter : 300/599,  Loss: 0.2567, Accuracy=91.000000\n",
      "Epoch : 4/5, Iter : 400/599,  Loss: 0.2595, Accuracy=90.000000\n",
      "Epoch : 4/5, Iter : 500/599,  Loss: 0.2380, Accuracy=91.000000\n",
      "Epoch : 4/5, Iter : 600/599,  Loss: 0.2037, Accuracy=92.929293\n",
      "Epoch : 5/5, Iter : 100/599,  Loss: 0.2085, Accuracy=94.000000\n",
      "Epoch : 5/5, Iter : 200/599,  Loss: 0.1698, Accuracy=94.000000\n",
      "Epoch : 5/5, Iter : 300/599,  Loss: 0.3124, Accuracy=93.000000\n",
      "Epoch : 5/5, Iter : 400/599,  Loss: 0.1299, Accuracy=95.000000\n",
      "Epoch : 5/5, Iter : 500/599,  Loss: 0.1842, Accuracy=93.000000\n",
      "Epoch : 5/5, Iter : 600/599,  Loss: 0.2288, Accuracy=90.909091\n"
     ]
    }
   ],
   "source": [
    "#TRAINING THE MODEL\n",
    "losses = [];\n",
    "for epoch in range(num_epochs):\n",
    "    for i, (images, labels) in enumerate(train_loader):\n",
    "        images = Variable(images.float())\n",
    "        labels = Variable(labels)\n",
    "        correct=0\n",
    "        total=0\n",
    "        # Forward + Backward + Optimize\n",
    "        optimizer.zero_grad()\n",
    "        outputs = cnn(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        #outputs=model(images)\n",
    "        _, predicted=torch.max(outputs.data,1)\n",
    "        total+=labels.size(0)\n",
    "        correct+= (predicted==labels).sum()\n",
    "        accuracy=100*(float(correct)/float(total))\n",
    "        losses.append(loss.data[0]);\n",
    "        \n",
    "        if (i+1) % 100 == 0:\n",
    "            print ('Epoch : %d/%d, Iter : %d/%d,  Loss: %.4f, Accuracy=%f' \n",
    "                   %(epoch+1, num_epochs, i+1, len(train_dataset)//batch_size, loss.data[0], accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy of the model on the 10000 test images: 91.0000 %\n"
     ]
    }
   ],
   "source": [
    "#EVALUATING THE FINAL ACCURACY OF THE MODEL\n",
    "cnn.eval()\n",
    "correct = 0\n",
    "total = 0\n",
    "for images, labels in test_loader:\n",
    "    images = Variable(images.float())\n",
    "    outputs = cnn(images)\n",
    "    _, predicted = torch.max(outputs.data, 1)\n",
    "    total += labels.size(0)\n",
    "    correct += (predicted == labels).sum()\n",
    "print('Test Accuracy of the model on the 10000 test images: %.4f %%' % (100 * correct / total))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "In the above model, we haven't used BatchNorm or Dropout and we got the accuracy of 91%\n",
    "However, as shown using the comments, if we use only Batchnorm, the accuracy increases to 93%\n",
    "On the other hand, using only dropout gets the final accuracy down to 89%\n",
    "Another scenario is to use both the functions together which gives an accuracy of 92%\n",
    "\"\"\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
